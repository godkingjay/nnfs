# Import Libraries


# Layer Dense
# Dense Class


# Activation
# Rectified Linear Unit (ReLU) Activation Class


# Softmax Activation Class


# Loss
# Loss Class


# Categorical Cross-Entropy Loss Class


# Loss and Activation
# Categorical Cross-Entropy Loss and Softmax Activation Class


# Optimizer
# Stochastic Gradient Descent (SGD) Optimizer Class


# Accuracy Class


# Initialize Dataset


# Create 1st Dense Layer with 2 input features and 64 output values


# Create ReLU Activation (to be used with Dense Layer):


# Create 2nd Dense Layer (64 input features from prev layer and 3 output values)


# Create Softmax classifier's combined loss and activation


# Create Optimizer


# Train in loop
